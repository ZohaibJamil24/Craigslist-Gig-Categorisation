{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Group 12 - Python Code ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imported the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dipitabiswas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dipitabiswas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dipitabiswas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loaded the dataset (939 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 939\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_datetime</th>\n",
       "      <th>post_title_link</th>\n",
       "      <th>post_title_text</th>\n",
       "      <th>post_hood</th>\n",
       "      <th>detail_body</th>\n",
       "      <th>Completed</th>\n",
       "      <th>pay_from_post</th>\n",
       "      <th>pay_rate</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-26T16:16:39.000Z</td>\n",
       "      <td>https://boston.craigslist.org/gbs/lbg/75385228...</td>\n",
       "      <td>* Deliver with DoorDash *</td>\n",
       "      <td>boston/cambridge/brookline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lump</td>\n",
       "      <td>Far skin small then. Gig available immediately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-26T16:13:53.000Z</td>\n",
       "      <td>https://boston.craigslist.org/gbs/dmg/75385300...</td>\n",
       "      <td>Up to $300 Paid Research for Toyota / Lexus Dr...</td>\n",
       "      <td>Boston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>300.0</td>\n",
       "      <td>lump</td>\n",
       "      <td>Need part-time driver, flexible hours, pay per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-26T16:08:33.000Z</td>\n",
       "      <td>https://boston.craigslist.org/gbs/lbg/75385227...</td>\n",
       "      <td>Grubhub Delivery Driver - No Experience Needed!</td>\n",
       "      <td>Boston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hourly</td>\n",
       "      <td>Urgent delivery gig: lightweight items, 2-4 ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-09-26T15:57:42.000Z</td>\n",
       "      <td>https://boston.craigslist.org/gbs/tlg/75385206...</td>\n",
       "      <td>The most fun work at live events! 52,000 real ...</td>\n",
       "      <td>Greater Boston area</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>hourly</td>\n",
       "      <td>Event gig: greeting guests, handing out materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-09-26T15:44:01.000Z</td>\n",
       "      <td>https://boston.craigslist.org/gbs/lbg/75385138...</td>\n",
       "      <td>ðŸ’¸ðŸ“ˆðŸ’¸ðŸ“ˆLAWN CARE PROS - MAKE UP TO $1000 PER WEEK</td>\n",
       "      <td>boston/cambridge/brookline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>weekly</td>\n",
       "      <td>Into heart speak challenge turn. Gig available...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             post_datetime  \\\n",
       "0           0  2022-09-26T16:16:39.000Z   \n",
       "1           1  2022-09-26T16:13:53.000Z   \n",
       "2           2  2022-09-26T16:08:33.000Z   \n",
       "3           3  2022-09-26T15:57:42.000Z   \n",
       "4           4  2022-09-26T15:44:01.000Z   \n",
       "\n",
       "                                     post_title_link  \\\n",
       "0  https://boston.craigslist.org/gbs/lbg/75385228...   \n",
       "1  https://boston.craigslist.org/gbs/dmg/75385300...   \n",
       "2  https://boston.craigslist.org/gbs/lbg/75385227...   \n",
       "3  https://boston.craigslist.org/gbs/tlg/75385206...   \n",
       "4  https://boston.craigslist.org/gbs/lbg/75385138...   \n",
       "\n",
       "                                     post_title_text  \\\n",
       "0                          * Deliver with DoorDash *   \n",
       "1  Up to $300 Paid Research for Toyota / Lexus Dr...   \n",
       "2    Grubhub Delivery Driver - No Experience Needed!   \n",
       "3  The most fun work at live events! 52,000 real ...   \n",
       "4     ðŸ’¸ðŸ“ˆðŸ’¸ðŸ“ˆLAWN CARE PROS - MAKE UP TO $1000 PER WEEK   \n",
       "\n",
       "                    post_hood  detail_body  Completed  pay_from_post pay_rate  \\\n",
       "0  boston/cambridge/brookline          NaN       True            NaN     lump   \n",
       "1                      Boston          NaN       True          300.0     lump   \n",
       "2                      Boston          NaN       True            NaN   hourly   \n",
       "3         Greater Boston area          NaN       True           30.0   hourly   \n",
       "4  boston/cambridge/brookline          NaN       True         1000.0   weekly   \n",
       "\n",
       "                                         description  \n",
       "0  Far skin small then. Gig available immediately...  \n",
       "1  Need part-time driver, flexible hours, pay per...  \n",
       "2  Urgent delivery gig: lightweight items, 2-4 ho...  \n",
       "3  Event gig: greeting guests, handing out materi...  \n",
       "4  Into heart speak challenge turn. Gig available...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"Craigslist_Gigs_Boston.csv\")  \n",
    "\n",
    "# Check\n",
    "print(\"Rows:\", df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Data (Lower case, Lemmatization, Stop words removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dipitabiswas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dipitabiswas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>clean_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Far skin small then. Gig available immediately...</td>\n",
       "      <td>far skin small gig available immediately local...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Need part-time driver, flexible hours, pay per...</td>\n",
       "      <td>need parttime driver flexible hour pay per trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urgent delivery gig: lightweight items, 2-4 ho...</td>\n",
       "      <td>urgent delivery gig lightweight item hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Event gig: greeting guests, handing out materi...</td>\n",
       "      <td>event gig greeting guest handing material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Into heart speak challenge turn. Gig available...</td>\n",
       "      <td>heart speak challenge turn gig available immed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Far skin small then. Gig available immediately...   \n",
       "1  Need part-time driver, flexible hours, pay per...   \n",
       "2  Urgent delivery gig: lightweight items, 2-4 ho...   \n",
       "3  Event gig: greeting guests, handing out materi...   \n",
       "4  Into heart speak challenge turn. Gig available...   \n",
       "\n",
       "                                   clean_description  \n",
       "0  far skin small gig available immediately local...  \n",
       "1    need parttime driver flexible hour pay per trip  \n",
       "2          urgent delivery gig lightweight item hour  \n",
       "3          event gig greeting guest handing material  \n",
       "4  heart speak challenge turn gig available immed...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text_lite(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()  \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "df['clean_description'] = df['description'].apply(preprocess_text_lite)\n",
    "\n",
    "# Preview\n",
    "df[['description', 'clean_description']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Frequency Normalization (TF-IDF with 1â€“2 grams, min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (939, 1041)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF \n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3)\n",
    "X = vectorizer.fit_transform(df['clean_description'])\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Modeling: K-Means Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Keywords per Cluster:\n",
      "\n",
      "Cluster 0: area, site, immediately local, available, local area, gig available, immediately, available immediately, senior, local\n",
      "Cluster 1: need, assist, furniture, needed, assist moving, moving, driver, help, box, parttime\n",
      "Cluster 2: act, let, tax, area, local area, available immediately, available, immediately, immediately local, gig available\n",
      "Cluster 3: area, local, available, immediately, gig available, available immediately, immediately local, local area, gig, event\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 4  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Top keywords per cluster\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(\"\\nTop 10 Keywords per Cluster:\\n\")\n",
    "for i in range(k):\n",
    "    top_terms = [terms[ind] for ind in order_centroids[i, :10]]\n",
    "    print(f\"Cluster {i}: {', '.join(top_terms)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferred Themes from Clustering Output:\n",
    "\n",
    "\n",
    "Cluster 0 â€“ Location-Based Gig Availability:\n",
    "Keywords like area, site, immediately local, available, gig available, local area, senior suggest postings focused on local short-term gigs often involving specific locations or site-based tasks, possibly for elderly care or house help.\n",
    "\n",
    "Cluster 1 â€“ Moving & Manual Labor Assistance:\n",
    "Keywords like assist, furniture, moving, driver, help, box, parttime point to gigs that involve physical help or moving assistance, such as lifting, delivery, or driving.\n",
    "\n",
    "Cluster 2 â€“ Legal or Admin Tasks (Possible Spam/Irrelevant):\n",
    "Keywords like act, let, tax mixed with area, available immediately are a bit vague but may suggest legal or formal tasks or potentially spammy or unclear listings that reuse common tokens.\n",
    "\n",
    "Cluster 3 â€“ General Local Availability/Repeat Phrases:\n",
    "Keywords like area, local, available, immediately are highly repetitive and generic. This cluster likely captures general-purpose or poorly written gigs that frequently use availability phrases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Label Creation using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/dipitabiswas/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_label(text):\n",
    "    score = sid.polarity_scores(str(text))['compound']\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['sentiment_label'] = df['description'].apply(get_sentiment_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split (70/30) for Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 657\n",
      "Test size: 282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define X and y\n",
    "y = df['sentiment_label']\n",
    "\n",
    "# 70% train, 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training size:\", X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Validation: Naive Bayes Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Naive Bayes Classification Report ======\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        34\n",
      "     neutral       0.73      0.80      0.76       124\n",
      "    positive       0.68      0.81      0.74       124\n",
      "\n",
      "    accuracy                           0.71       282\n",
      "   macro avg       0.47      0.53      0.50       282\n",
      "weighted avg       0.62      0.71      0.66       282\n",
      "\n",
      "\n",
      "====== Confusion Matrix ======\n",
      "\n",
      "[[  0  12  22]\n",
      " [  0  99  25]\n",
      " [  0  24 100]]\n",
      "\n",
      "====== Accuracy Summary ======\n",
      "\n",
      "Naive Bayes Train Accuracy: 85.69%\n",
      "Naive Bayes Test Accuracy: 70.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on train and test sets\n",
    "y_pred_nb_train = nb_model.predict(X_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "#Calculate training and test accuracy\n",
    "train_accuracy_nb = accuracy_score(y_train, y_pred_nb_train)\n",
    "test_accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "#Evaluation results\n",
    "print(\"\\n====== Naive Bayes Classification Report ======\\n\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\n====== Confusion Matrix ======\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\n====== Accuracy Summary ======\\n\")\n",
    "print(f\"Naive Bayes Train Accuracy: {train_accuracy_nb * 100:.2f}%\")\n",
    "print(f\"Naive Bayes Test Accuracy: {test_accuracy_nb * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Validation: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Logistic Regression Classification Report ======\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        34\n",
      "     neutral       0.70      0.84      0.76       124\n",
      "    positive       0.71      0.76      0.73       124\n",
      "\n",
      "    accuracy                           0.70       282\n",
      "   macro avg       0.47      0.53      0.50       282\n",
      "weighted avg       0.62      0.70      0.66       282\n",
      "\n",
      "\n",
      "====== Confusion Matrix ======\n",
      "\n",
      "[[  0  15  19]\n",
      " [  0 104  20]\n",
      " [  0  30  94]]\n",
      "\n",
      "====== Accuracy Summary ======\n",
      "\n",
      "Logistic Regression Train Accuracy: 89.95%\n",
      "Logistic Regression Test Accuracy: 70.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on train and test sets\n",
    "y_pred_lr_train = lr_model.predict(X_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "train_accuracy_lr = accuracy_score(y_train, y_pred_lr_train)\n",
    "test_accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "# Evaluation results\n",
    "print(\"\\n====== Logistic Regression Classification Report ======\\n\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\n====== Confusion Matrix ======\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\n====== Accuracy Summary ======\\n\")\n",
    "print(f\"Logistic Regression Train Accuracy: {train_accuracy_lr * 100:.2f}%\")\n",
    "print(f\"Logistic Regression Test Accuracy: {test_accuracy_lr * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Validation: Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Random Forest Classification Report ======\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        34\n",
      "     neutral       0.67      0.77      0.72       124\n",
      "    positive       0.65      0.73      0.69       124\n",
      "\n",
      "    accuracy                           0.66       282\n",
      "   macro avg       0.44      0.50      0.47       282\n",
      "weighted avg       0.58      0.66      0.62       282\n",
      "\n",
      "\n",
      "====== Confusion Matrix ======\n",
      "\n",
      "[[ 0 14 20]\n",
      " [ 0 96 28]\n",
      " [ 0 33 91]]\n",
      "\n",
      "====== Accuracy Summary ======\n",
      "\n",
      "Random Forest Train Accuracy: 100.00%\n",
      "Random Forest Test Accuracy: 66.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/gba462p/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on train and test sets\n",
    "y_pred_rf_train = rf_model.predict(X_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "train_accuracy_rf = accuracy_score(y_train, y_pred_rf_train)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Evaluation results\n",
    "print(\"\\n====== Random Forest Classification Report ======\\n\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\n====== Confusion Matrix ======\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\n====== Accuracy Summary ======\\n\")\n",
    "print(f\"Random Forest Train Accuracy: {train_accuracy_rf * 100:.2f}%\")\n",
    "print(f\"Random Forest Test Accuracy: {test_accuracy_rf * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Validation: Support Vector Machine (SVM) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== SVM Classification Report ======\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.18      0.25        34\n",
      "     neutral       0.71      0.82      0.76       124\n",
      "    positive       0.74      0.74      0.74       124\n",
      "\n",
      "    accuracy                           0.71       282\n",
      "   macro avg       0.63      0.58      0.58       282\n",
      "weighted avg       0.69      0.71      0.69       282\n",
      "\n",
      "\n",
      "====== Confusion Matrix ======\n",
      "\n",
      "[[  6  14  14]\n",
      " [  3 102  19]\n",
      " [  5  27  92]]\n",
      "\n",
      "====== Accuracy Summary ======\n",
      "\n",
      "SVM Train Accuracy: 100.00%\n",
      "SVM Test Accuracy: 70.92%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = LinearSVC(random_state=42, max_iter=10000)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on train and test sets\n",
    "y_pred_svm_train = svm_model.predict(X_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "train_accuracy_svm = accuracy_score(y_train, y_pred_svm_train)\n",
    "test_accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# Step 5: Print evaluation results\n",
    "print(\"\\n====== SVM Classification Report ======\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\n====== Confusion Matrix ======\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\n====== Accuracy Summary ======\\n\")\n",
    "print(f\"SVM Train Accuracy: {train_accuracy_svm * 100:.2f}%\")\n",
    "print(f\"SVM Test Accuracy: {test_accuracy_svm * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Validation: Decision Tree Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Decision Tree Classification Report ======\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.42      0.24      0.30        34\n",
      "     neutral       0.73      0.86      0.79       124\n",
      "    positive       0.78      0.73      0.75       124\n",
      "\n",
      "    accuracy                           0.73       282\n",
      "   macro avg       0.64      0.61      0.61       282\n",
      "weighted avg       0.71      0.73      0.71       282\n",
      "\n",
      "\n",
      "====== Confusion Matrix ======\n",
      "\n",
      "[[  8  13  13]\n",
      " [  4 107  13]\n",
      " [  7  27  90]]\n",
      "\n",
      "====== Accuracy Summary ======\n",
      "\n",
      "Decision Tree Train Accuracy: 100.00%\n",
      "Decision Tree Test Accuracy: 72.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on train and test sets\n",
    "y_pred_dt_train = dt_model.predict(X_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "train_accuracy_dt = accuracy_score(y_train, y_pred_dt_train)\n",
    "test_accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "# Evaluation results\n",
    "print(\"\\n====== Decision Tree Classification Report ======\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"\\n====== Confusion Matrix ======\\n\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "print(\"\\n====== Accuracy Summary ======\\n\")\n",
    "print(f\"Decision Tree Train Accuracy: {train_accuracy_dt * 100:.2f}%\")\n",
    "print(f\"Decision Tree Test Accuracy: {test_accuracy_dt * 100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gba462p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
